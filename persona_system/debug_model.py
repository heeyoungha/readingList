"""
ëª¨ë¸ ì¶”ë¡  ë¬¸ì œ ë””ë²„ê¹…
"""
import sys
from pathlib import Path
import torch
from transformers import AutoTokenizer, AutoModel
from loguru import logger

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_model_directly():
    """ëª¨ë¸ì„ ì§ì ‘ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  ëª¨ë¸ ì§ì ‘ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # ëª¨ë¸ ë¡œë“œ
        model_name = "klue/roberta-base"
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”©: {model_name}")
        
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModel.from_pretrained(model_name)
        device = torch.device("cpu")
        model.to(device)
        model.eval()
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
        test_text = "ì•ˆë…•í•˜ì„¸ìš”"
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸: '{test_text}'")
        
        # í† í¬ë‚˜ì´ì§•
        print("ğŸ”„ í† í¬ë‚˜ì´ì§•...")
        inputs = tokenizer(
            test_text,
            return_tensors="pt",
            max_length=512,
            truncation=True,
            padding=True
        )
        print(f"âœ… í† í¬ë‚˜ì´ì§• ì™„ë£Œ: {inputs['input_ids'].shape}")
        
        # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        print("ğŸ“± ë””ë°”ì´ìŠ¤ë¡œ ì´ë™...")
        inputs = {k: v.to(device) for k, v in inputs.items()}
        print("âœ… ë””ë°”ì´ìŠ¤ ì´ë™ ì™„ë£Œ")
        
        # ëª¨ë¸ ì¶”ë¡ 
        print("ğŸ§  ëª¨ë¸ ì¶”ë¡  ì‹œì‘...")
        with torch.no_grad():
            outputs = model(**inputs)
            print(f"âœ… ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ: {outputs.last_hidden_state.shape}")
        
        print("ğŸ‰ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        return True
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def test_embedding_generator():
    """EmbeddingGenerator í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("ğŸ”§ EmbeddingGenerator í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    try:
        from utils.embedding_generator import EmbeddingGenerator
        
        print("ğŸ“¥ EmbeddingGenerator ìƒì„±...")
        embedding_gen = EmbeddingGenerator()
        
        print("ğŸ“ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ ì„ë² ë”© ìƒì„±...")
        test_texts = ["ì•ˆë…•í•˜ì„¸ìš”", "í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤"]
        
        result = embedding_gen.generate_embeddings(test_texts)
        print(f"âœ… ì„ë² ë”© ìƒì„± ì„±ê³µ: {result['embeddings'].shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ EmbeddingGenerator í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

if __name__ == "__main__":
    print("ğŸ” ëª¨ë¸ ì¶”ë¡  ë¬¸ì œ ë””ë²„ê¹… ì‹œì‘")
    print("="*60)
    
    # 1. ëª¨ë¸ ì§ì ‘ í…ŒìŠ¤íŠ¸
    success1 = test_model_directly()
    
    # 2. EmbeddingGenerator í…ŒìŠ¤íŠ¸
    if success1:
        success2 = test_embedding_generator()
    else:
        print("âŒ ëª¨ë¸ ì§ì ‘ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¡œ EmbeddingGenerator í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€")
        success2 = False
    
    print("\n" + "="*60)
    print("ğŸ¯ ë””ë²„ê¹… ê²°ê³¼ ìš”ì•½")
    print("="*60)
    print(f"ëª¨ë¸ ì§ì ‘ í…ŒìŠ¤íŠ¸: {'âœ… ì„±ê³µ' if success1 else 'âŒ ì‹¤íŒ¨'}")
    print(f"EmbeddingGenerator í…ŒìŠ¤íŠ¸: {'âœ… ì„±ê³µ' if success2 else 'âŒ ì‹¤íŒ¨'}") 