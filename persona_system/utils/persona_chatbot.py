"""
ðŸ¤– Phase 4: íŽ˜ë¥´ì†Œë‚˜ ì±—ë´‡ ê°œë°œ

OpenAI API ì—°ë™, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, RAG íŒŒì´í”„ë¼ì¸ êµ¬ì„±, ê°œì¸ ë§žì¶¤í˜• í”„ë¡œì íŠ¸ ì¶”ì²œ
"""
import os
import json
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from loguru import logger

try:
    import openai
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logger.warning("OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì±—ë´‡ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

from .search_system import SearchSystem
import sys
from pathlib import Path
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
from config import get_openai_api_key


class PersonaChatbot:
    """Phase 4: ê°œì¸ ë§žì¶¤í˜• íŽ˜ë¥´ì†Œë‚˜ ì±—ë´‡"""
    
    def __init__(self, 
                 search_system: Optional[SearchSystem] = None,
                 model_name: str = "gpt-3.5-turbo",
                 max_tokens: int = 1000,
                 temperature: float = 0.7):
        """
        íŽ˜ë¥´ì†Œë‚˜ ì±—ë´‡ ì´ˆê¸°í™”
        
        Args:
            search_system: ê²€ìƒ‰ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
            model_name: OpenAI ëª¨ë¸ëª…
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            temperature: ìƒì„± ì˜¨ë„ (0.0-1.0)
        """
        self.model_name = model_name
        self.max_tokens = max_tokens
        self.temperature = temperature
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = None
        self.api_key = get_openai_api_key()
        
        if OPENAI_AVAILABLE and self.api_key:
            self.client = OpenAI(api_key=self.api_key)
            logger.info("âœ… OpenAI API ì—°ë™ ì™„ë£Œ")
        else:
            logger.warning("âŒ OpenAI API ì‚¬ìš© ë¶ˆê°€ - API í‚¤ í™•ì¸ í•„ìš”")
        
        # ê²€ìƒ‰ ì‹œìŠ¤í…œ ì—°ë™
        self.search_system = search_system or SearchSystem()
        
        # ëŒ€í™” ížˆìŠ¤í† ë¦¬ ê´€ë¦¬
        self.conversation_history = []
        
        logger.info("ðŸ¤– Phase 4 íŽ˜ë¥´ì†Œë‚˜ ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"  - ëª¨ë¸: {model_name}")
        logger.info(f"  - ìµœëŒ€ í† í°: {max_tokens}")
        logger.info(f"  - ì˜¨ë„: {temperature}")
    
    def _create_persona_prompt(self, user_context: str, search_results: List[Dict[str, Any]]) -> str:
        """
        ê°œì¸ ë§žì¶¤í˜• íŽ˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            user_context: ì‚¬ìš©ìž ì»¨í…ìŠ¤íŠ¸ (ì§ˆë¬¸, ê´€ì‹¬ì‚¬ ë“±)
            search_results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸
        """
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        context_info = self.search_system.compose_search_context(search_results)
        context_text = context_info['context_text']
        
        # íŽ˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        persona_prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìžì˜ ë…ì„œ íŒ¨í„´ê³¼ ê´€ì‹¬ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì¸ ë§žì¶¤í˜• í”„ë¡œì íŠ¸ë¥¼ ì¶”ì²œí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤.

## ë‹¹ì‹ ì˜ ì—­í• :
1. ì‚¬ìš©ìžì˜ ë…í›„ê°, ì•¡ì…˜ ë¦¬ìŠ¤íŠ¸, ê´€ì‹¬ì‚¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŽ˜ë¥´ì†Œë‚˜ë¥¼ íŒŒì•…
2. ì°½ì˜ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ì œì•ˆ
3. ì‚¬ìš©ìžì˜ ì„±í–¥ê³¼ ëŠ¥ë ¥ì— ë§žëŠ” êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆ ì œì‹œ
4. ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ í†¤ìœ¼ë¡œ ëŒ€í™”

## ì‚¬ìš©ìž ê´€ë ¨ ì •ë³´:
{context_text}

## ì‚¬ìš©ìž ì§ˆë¬¸:
{user_context}

## ë‹µë³€ ê°€ì´ë“œë¼ì¸:
- ìœ„ì˜ ì‚¬ìš©ìž ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ ì¶”ì²œ ì œê³µ
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ì œì‹œ
- ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš í¬í•¨
- ì‚¬ìš©ìžì˜ ê´€ì‹¬ì‚¬ì™€ ì—°ê²°ëœ ì°½ì˜ì  ì ‘ê·¼
- í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ê²©ë ¤ì ì¸ í†¤ ì‚¬ìš©

ë‹µë³€:"""
        
        return persona_prompt
    
    def _create_general_prompt(self, user_question: str) -> str:
        """
        ì¼ë°˜ì ì¸ ëŒ€í™” í”„ë¡¬í”„íŠ¸ ìƒì„± (ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ)
        
        Args:
            user_question: ì‚¬ìš©ìž ì§ˆë¬¸
            
        Returns:
            ì¼ë°˜ í”„ë¡¬í”„íŠ¸
        """
        general_prompt = f"""ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ëŠ” ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤.

## ë‹¹ì‹ ì˜ ì—­í• :
1. ì‚¬ìš©ìžì˜ ê´€ì‹¬ì‚¬ì— ë§žëŠ” ì°½ì˜ì  í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ì œì•ˆ
2. ì‹¤í˜„ ê°€ëŠ¥í•˜ê³  êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆ ì œì‹œ
3. ë‹¨ê³„ë³„ ê°€ì´ë“œ ë° í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ì•ˆë‚´
4. ê²©ë ¤ì ì´ê³  ë™ê¸°ë¶€ì—¬ê°€ ë˜ëŠ” ëŒ€í™”

## ì‚¬ìš©ìž ì§ˆë¬¸:
{user_question}

## ë‹µë³€ ê°€ì´ë“œë¼ì¸:
- ì°½ì˜ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ ì œì‹œ
- êµ¬ì²´ì ì¸ ì‹¤í–‰ ë‹¨ê³„ í¬í•¨
- í•„ìš”í•œ ë„êµ¬ë‚˜ ë¦¬ì†ŒìŠ¤ ì•ˆë‚´
- í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ê²©ë ¤ì ì¸ í†¤ ì‚¬ìš©

ë‹µë³€:"""
        
        return general_prompt
    
    def generate_project_recommendations(self, 
                                       user_question: str,
                                       search_k: int = 5,
                                       use_conversation_history: bool = True) -> Dict[str, Any]:
        """
        ê°œì¸ ë§žì¶¤í˜• í”„ë¡œì íŠ¸ ì¶”ì²œ ìƒì„±
        
        Args:
            user_question: ì‚¬ìš©ìž ì§ˆë¬¸
            search_k: ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜
            use_conversation_history: ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            ì¶”ì²œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info(f"ðŸ¤– í”„ë¡œì íŠ¸ ì¶”ì²œ ìƒì„± ì‹œìž‘: '{user_question}'")
        
        try:
            # 1. ì˜ë¯¸ì  ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            search_results = self.search_system.semantic_search(user_question, k=search_k)
            
            # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
            if search_results:
                prompt = self._create_persona_prompt(user_question, search_results)
                prompt_type = "persona"
            else:
                prompt = self._create_general_prompt(user_question)
                prompt_type = "general"
            
            # 3. ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì¶”ê°€
            messages = []
            if use_conversation_history and self.conversation_history:
                # ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ í¬í•¨
                recent_history = self.conversation_history[-6:]  # user + assistant ìŒìœ¼ë¡œ 3ê°œ
                messages.extend(recent_history)
            
            # í˜„ìž¬ ì§ˆë¬¸ ì¶”ê°€
            messages.append({"role": "user", "content": prompt})
            
            # 4. OpenAI API í˜¸ì¶œ
            if not self.client:
                return {
                    "success": False,
                    "error": "OpenAI API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "search_results": search_results,
                    "prompt_type": prompt_type
                }
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            # 5. ì‘ë‹µ ì²˜ë¦¬
            ai_response = response.choices[0].message.content
            
            # 6. ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            self.conversation_history.append({"role": "user", "content": user_question})
            self.conversation_history.append({"role": "assistant", "content": ai_response})
            
            # ížˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ (ìµœëŒ€ 10ê°œ êµí™˜)
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
            
            # 7. ê²°ê³¼ êµ¬ì„±
            result = {
                "success": True,
                "recommendation": ai_response,
                "search_results": search_results,
                "context_used": len(search_results) > 0,
                "prompt_type": prompt_type,
                "metadata": {
                    "model": self.model_name,
                    "tokens_used": response.usage.total_tokens,
                    "search_count": len(search_results),
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            logger.info(f"âœ… í”„ë¡œì íŠ¸ ì¶”ì²œ ìƒì„± ì™„ë£Œ")
            logger.info(f"  - í† í° ì‚¬ìš©: {response.usage.total_tokens}")
            logger.info(f"  - ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ")
            logger.info(f"  - í”„ë¡¬í”„íŠ¸ íƒ€ìž…: {prompt_type}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ í”„ë¡œì íŠ¸ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "search_results": search_results if 'search_results' in locals() else [],
                "prompt_type": prompt_type if 'prompt_type' in locals() else "unknown"
            }
    
    def analyze_user_persona(self, user_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ì‚¬ìš©ìž ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŽ˜ë¥´ì†Œë‚˜ ë¶„ì„
        
        Args:
            user_data: ì‚¬ìš©ìž ë…í›„ê°, ì•¡ì…˜ ë¦¬ìŠ¤íŠ¸ ë“±ì˜ ë°ì´í„°
            
        Returns:
            íŽ˜ë¥´ì†Œë‚˜ ë¶„ì„ ê²°ê³¼
        """
        logger.info(f"ðŸ‘¤ ì‚¬ìš©ìž íŽ˜ë¥´ì†Œë‚˜ ë¶„ì„ ì‹œìž‘: {len(user_data)}ê°œ ë°ì´í„°")
        
        try:
            # ë°ì´í„° ìš”ì•½
            data_summary = []
            for item in user_data[:10]:  # ìµœëŒ€ 10ê°œë§Œ ë¶„ì„
                content = item.get('content', '')[:200]  # 200ìžë¡œ ì œí•œ
                data_type = item.get('type', 'unknown')
                data_summary.append(f"[{data_type}] {content}")
            
            summary_text = "\n".join(data_summary)
            
            # íŽ˜ë¥´ì†Œë‚˜ ë¶„ì„ í”„ë¡¬í”„íŠ¸
            analysis_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ìžì˜ ë…ì„œ ë° í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŽ˜ë¥´ì†Œë‚˜ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ìž ë°ì´í„°:
{summary_text}

## ë¶„ì„ ìš”ì²­ì‚¬í•­:
1. ì£¼ìš” ê´€ì‹¬ ë¶„ì•¼ (ìµœëŒ€ 5ê°œ)
2. í•™ìŠµ ìŠ¤íƒ€ì¼ íŠ¹ì„±
3. í”„ë¡œì íŠ¸ ì„ í˜¸ë„ (ì´ë¡ ì  vs ì‹¤ìš©ì )
4. ì°½ì˜ì„± ìˆ˜ì¤€
5. ì¶”ì²œ í”„ë¡œì íŠ¸ ë°©í–¥ì„±

## ì¶œë ¥ í˜•ì‹:
JSON í˜•íƒœë¡œ ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥í•´ì£¼ì„¸ìš”:
{{
  "interests": ["ê´€ì‹¬ë¶„ì•¼1", "ê´€ì‹¬ë¶„ì•¼2", ...],
  "learning_style": "í•™ìŠµ ìŠ¤íƒ€ì¼ ì„¤ëª…",
  "project_preference": "í”„ë¡œì íŠ¸ ì„ í˜¸ë„ ì„¤ëª…",
  "creativity_level": "ì°½ì˜ì„± ìˆ˜ì¤€ (1-5)",
  "recommendations": "ì¶”ì²œ ë°©í–¥ì„± ì„¤ëª…"
}}"""
            
            if not self.client:
                return {
                    "success": False,
                    "error": "OpenAI API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": analysis_prompt}],
                max_tokens=800,
                temperature=0.3  # ë¶„ì„ì€ ë” ì¼ê´€ì„± ìžˆê²Œ
            )
            
            ai_response = response.choices[0].message.content
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json ... ``` í˜•íƒœì¼ ìˆ˜ ìžˆìŒ)
                import re
                json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
                if json_match:
                    persona_data = json.loads(json_match.group())
                else:
                    # JSONì´ ì•„ë‹Œ ê²½ìš° í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                    persona_data = {"analysis": ai_response}
            except:
                persona_data = {"analysis": ai_response}
            
            result = {
                "success": True,
                "persona": persona_data,
                "raw_response": ai_response,
                "data_count": len(user_data),
                "metadata": {
                    "model": self.model_name,
                    "tokens_used": response.usage.total_tokens,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            logger.info(f"âœ… íŽ˜ë¥´ì†Œë‚˜ ë¶„ì„ ì™„ë£Œ")
            logger.info(f"  - í† í° ì‚¬ìš©: {response.usage.total_tokens}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ íŽ˜ë¥´ì†Œë‚˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "data_count": len(user_data) if user_data else 0
            }
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """
        í˜„ìž¬ ëŒ€í™” ì„¸ì…˜ ìš”ì•½ ë°˜í™˜
        
        Returns:
            ëŒ€í™” ìš”ì•½ ì •ë³´
        """
        return {
            "total_exchanges": len(self.conversation_history) // 2,
            "last_interaction": self.conversation_history[-1] if self.conversation_history else None,
            "conversation_started": len(self.conversation_history) > 0,
            "history_length": len(self.conversation_history)
        }
    
    def clear_conversation_history(self):
        """ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_history = []
        logger.info("ðŸ—‘ï¸ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def save_conversation(self, file_path: str):
        """
        ëŒ€í™” ížˆìŠ¤í† ë¦¬ë¥¼ íŒŒì¼ë¡œ ì €ìž¥
        
        Args:
            file_path: ì €ìž¥í•  íŒŒì¼ ê²½ë¡œ
        """
        try:
            conversation_data = {
                "conversation_history": self.conversation_history,
                "metadata": {
                    "model": self.model_name,
                    "total_exchanges": len(self.conversation_history) // 2,
                    "saved_at": datetime.now().isoformat()
                }
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(conversation_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ðŸ’¾ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì €ìž¥ ì™„ë£Œ: {file_path}")
            
        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì €ìž¥ ì‹¤íŒ¨: {e}")
    
    def load_conversation(self, file_path: str):
        """
        íŒŒì¼ì—ì„œ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ë¡œë“œ
        
        Args:
            file_path: ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                conversation_data = json.load(f)
            
            self.conversation_history = conversation_data.get('conversation_history', [])
            
            logger.info(f"ðŸ“‚ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ë¡œë“œ ì™„ë£Œ: {file_path}")
            logger.info(f"  - ë¡œë“œëœ êµí™˜ ìˆ˜: {len(self.conversation_history) // 2}")
            
        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """
        ì±—ë´‡ ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜
        
        Returns:
            ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´
        """
        return {
            "openai_available": OPENAI_AVAILABLE,
            "api_key_configured": bool(self.api_key),
            "client_initialized": self.client is not None,
            "search_system_ready": self.search_system is not None,
            "model": self.model_name,
            "conversation_active": len(self.conversation_history) > 0,
            "conversation_exchanges": len(self.conversation_history) // 2
        } 